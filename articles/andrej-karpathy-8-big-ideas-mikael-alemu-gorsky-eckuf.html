<html>
<head>
  <title>Andrej Karpathy: 8 big ideas</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img class="series-logo" src="https://media.licdn.com/dms/image/v2/D4D12AQEfmvWDvno3mg/series-logo_image-shrink_300_300/series-logo_image-shrink_300_300/0/1726763056922?e=1754524800&v=beta&t=yDjwvI9T-dZ4fE5WvZZELb-Qjf3wgc7WRrFECKBQX9Q" />
    <h3>
      <span class="series-title">The AI Pravda</span>
      </br>
      <span class="series-description">Generative AI will change the world as we know it. Let's get prepared. </span>
    </h3>
    <img src="https://media.licdn.com/mediaD4E12AQEoTyt8agh3jg" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/andrej-karpathy-8-big-ideas-mikael-alemu-gorsky-eckuf">Andrej Karpathy: 8 big ideas</a></h1>
    <p class="created">Created on 2024-10-01 23:01</p>
  <p class="published">Published on 2024-10-02 04:30</p>
  <div><p>Here are 8 most interesting ideas/concepts that Andrej Karpathy have explained on “No Priors” podcast in September of 2024.&nbsp;</p><ul><li><p>What is the difference between Tesla’s and Waymo’s approach to self-driving cars, and why Tesla’s approach is better.</p></li><li><p>Future of software, and why there would be no program code in Tesla cars.</p></li><li><p>How Tesla is robotics company, and cars are actually robots.</p></li><li><p>The future of robotics business - will it be B2C or B2B.</p></li><li><p>Why humanoid robots have the optimal form factor.</p></li><li><p>Andrej is confident that the ideal size for LLM is ~1 billion parameters</p></li><li><p>Companies of LLMs</p></li><li><p>AI in education: humans develop curriculum and LLM is delivering it.</p></li></ul><h3>Self-driving cars: Tesla vs Waymo</h3><p>[Different approach to self-driving cars of Waymo (division of Google) vs Tesla: Waymo operates cars equipped with vast array of complex sensors while Tesla’s cars only use cameras.]</p><p>Tesla is using a lot of sensors, too.&nbsp; They just do it at training time.&nbsp; There are a bunch of cars that drive around with LiDARs… And they do mapping and all this stuff.&nbsp; You're doing it at training time and then you're distilling that into a test time package that gets deployed to the cars and is vision only.&nbsp; And it's like an arbitrage on sensors and expense… I think it's brilliant strategy that I don't think is fully appreciated.</p><h3>Future of software, and why there would be no program code in Tesla cars</h3><p>Neural network can eat through the [programming] stack… When I joined Tesla, there was a ton of C++ code, and now there's much, much less C++ code in the code that runs in the car.&nbsp;</p><p>Neural network initially was just doing a detection on the image level, then it went for multiple images, it gives you prediction, then multiple images over time give you a prediction, and you're discarding C++ code. And eventually you're just giving steering commands.</p><p>… I do suspect that the end-to-end systems for Tesla in, say, 10 years, it is just a neural net. I mean, the videos stream into a neural net and commands come out.</p><h3>Cars are robots, Tesla is robotics company</h3><p>I think cars are basically robots when you look at it. Cars are robots. And Tesla… is a robotics company. “Robotics at scale” company... They're not building a single thing.&nbsp; They're building the machine that builds the thing, which is a whole separate thing… The early version of Optimus, the robot, thought that it was a car, as it had the exact same computer, same cameras.&nbsp; It was really funny because we were running the car networks on the robot, but it's walking around the office and so on.&nbsp; It was trying to recognize drivable space, but it's all just walking space… It thought it was driving, but it's actually moving through an environment.</p><p>There's so much in-house expertise for building robotics at Tesla: it's all the same tools… being reconfigured from a car… [Look at] the speed with which Optimus was started. Elon said, “we're doing this”, and people came with all the right tools and all these CAD models and all the supply chain stuff... You need all the same kinds of stuff, both on the hardware side, on the scaling stuff, and on the brains… As for the brains, there was also a ton of transfer, not just of the specific networks, but also the whole approach and the labeling team and how it all coordinates...</p><h3>B2C vs B2B in robotics</h3><p>I don't think B2C should be the right start point [for humanoid robots to go to market]…</p><p>I think the best customer is the company itself… Probably Tesla is going to do this: incubate it in the factory… doing maybe a lot of material handling, et cetera.</p><p>Then you go to B2B, to other companies that have massive warehouses…</p><p>And then once you incubate it in multiple companies, I think that's when you start to go into the B2C applications.</p><h3>Humanoid robots – is that a proper form factor</h3><p>I would say the humanoid aspect is also very appealing because people can teleoperate it very easily…[Also] “world is designed for humans”.&nbsp;</p><p>…people are under-appreciating the scale of a fixed cost that goes into any single platform… It makes a lot of sense to centralize that and have a single platform that can do all the things.&nbsp; …you benefit a ton from the transfer learning between the different tasks.&nbsp; And in AI, you really want a single neuron that is multitasking, doing lots of things.&nbsp; That's where you're getting all the intelligence and the capability from.</p><p>…If you're building a special purpose thing for any one thing, you're not going to benefit from a lot of the transferring between all the other tasks, if that makes sense.</p><h3>Ideal size for LLM is 1 billion parameters&nbsp;</h3><p>I do think that the current models are wasting a ton of capacity remembering stuff that doesn't matter. …we just need to get to the cognitive core.&nbsp; And I think the cognitive core can be extremely small, just this thing that thinks.&nbsp; And if it needs to look up information, it knows how to use different tools.</p><p>I think a billion parameters suffices to get you a good cognitive core representation, maybe even one billion is too much… Distillation works surprisingly well: get a really big model or a huge amount of computers or something like that supervising a very small model.&nbsp; And you can stuff a lot of capability into a very small model.</p><p>The internet is 0.01% cognition and 99.99% of information is garbage.</p><h3>Companies of LLMs&nbsp;</h3><p>I do think you want to benefit from parallelization [of LLMs].&nbsp; …I think we'll probably end up with companies of LLMs of different capabilities specialized to various unique domains.&nbsp; Maybe there's a programmer, et cetera, and it will actually start to resemble companies to a very large extent.&nbsp; You have the programmer and the program manager and similar kinds of roles of LLMs working in parallel and coming together and orchestrating computation on your behalf.&nbsp; …Like a swarm… with automatic escalation to other parts of the swarm, depending on the difficulty of the problem and the specialization.</p><p>Assuming the CEO is like a brilliant cloud model, and the workers can be a lot cheaper, maybe even open-source models or whatnot.</p><h3>AI in education&nbsp;</h3><p>I think people could go really far if they had the perfect curriculum for anything… and perfect tutor for all the subjects.&nbsp; … we can approach that with AI.</p><p>[These days] I'm building a single course on AI.&nbsp; But the question is how do you actually scale a class, if your target audience is 8 billion people on Earth?&nbsp; They speak different languages and they're at different capability levels, etc. How do you use AI to sort of like do the scaling of a really good teacher?&nbsp;</p><p>[Human] teachers should create course and the curriculum… I don't think the models are good enough to create a good course, but I think they're good to become the front end to the student and interpret the course to them.&nbsp; …so [human] teacher should not be the front end anymore.&nbsp; The teacher is on the back end designing the materials on the course and the AI is the front end and it can speak all the different languages and it's kind of like takes you through the course.</p><p>It's AITA (AI teaching assistant.&nbsp;</p><p>I think a lot of companies don't understand where the capability is today, and then they end up building things that are too ahead of what's available or maybe not ambitious enough.</p><p>…the low-hanging fruit, for example, is different languages. Super low-hanging fruit.&nbsp; I think the current models are actually really good at translation, basically, and can target the material and translate it at the spot.&nbsp; So I think a lot of things are low-hanging fruit.&nbsp; This adaptability to a person's background, I think, is not at the low-hanging fruit, but I don't think it's too high up or too much away.&nbsp; But that is something you definitely want, because not everyone is coming in with the same background.&nbsp; And also what's really helpful is if you're familiar with some other disciplines in the past, then it's really useful to make analogies to the things you know.&nbsp; And that's extremely powerful in education.&nbsp;</p><p>[This solution] actually works, not something that you can demo and work sometimes.&nbsp; So I just mean like it really works in the way a person would.</p><hr><p><em>Andrej Karpathy is one of top AI experts in the world and an excellent speaker on various AI topics. </em></p><p><em>Born and schooled at Bratislava, he then got his education (up to Ph.D.) in Canada and worked in GenAI industry as research scientist in OpenAI, then director of artificial intelligence at Tesla, then returned to OpenAI. </em></p><p><em>This February he left OpenAI and announced that he will be working on his own education project.</em></p></div>
</body>
</html>