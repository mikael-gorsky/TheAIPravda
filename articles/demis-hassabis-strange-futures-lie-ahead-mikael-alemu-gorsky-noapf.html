<html>
<head>
  <title>Demis Hassabis: “Strange futures that lie ahead”</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img class="series-logo" src="https://media.licdn.com/dms/image/v2/D4D12AQEfmvWDvno3mg/series-logo_image-shrink_300_300/series-logo_image-shrink_300_300/0/1726763056922?e=1754524800&v=beta&t=yDjwvI9T-dZ4fE5WvZZELb-Qjf3wgc7WRrFECKBQX9Q" />
    <h3>
      <span class="series-title">The AI Pravda</span>
      </br>
      <span class="series-description">Generative AI will change the world as we know it. Let's get prepared. </span>
    </h3>
    <img src="https://media.licdn.com/mediaD4D12AQHQu3JRQcQKkg" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/demis-hassabis-strange-futures-lie-ahead-mikael-alemu-gorsky-noapf">Demis Hassabis: “Strange futures that lie ahead”</a></h1>
    <p class="created">Created on 2025-05-26 02:15</p>
  <p class="published">Published on 2025-05-26 02:45</p>
  <div><h2>Did Goolgle “ate” “the AGI pill"? </h2><p>Hassabis acknowledged a significant shift within Google towards openly embracing and working towards Artificial General Intelligence (AGI). He suggests AGI might be closer than many previously thought, and this understanding is now permeating Google's broader strategy, with AI becoming a foundational, "horizontal layer."</p><p>o&nbsp;&nbsp; <strong>Quote:</strong> "I think you could sort of say “AGI-pilled” is maybe the right word, that we're quite close to this human-level general intelligence, maybe closer than people thought even a couple of years ago, and it's gonna have broad, cross-cutting impact. And I think there's another thing that you saw at the keynote. It's sort of literally popping up everywhere because it's this horizontal layer that's gonna underpin everything. And I think everyone is starting to understand that, and maybe a bit of the DeepMind ethos is bleeding into the general Google, which is great."</p><p>o&nbsp;&nbsp; <strong>Quote (on AGI timeline consistency and definition):</strong> "Well, first of all, there isn't that much difference in our timelines if he's just before 2030 and I'm just after. Also, my timeline's been pretty consistent since the start of DeepMind in 2010. So, we thought it was roughly a 20-year mission, and amazingly, we're on track... I have quite a high bar, which I've always had, which is it should be able to do all of the things that the human brain can do, right? Even theoretically. And so, that's a higher bar than, say, what the typical individual human could do..."</p><h2>AlphaEvolve: AI-Driven discovery and the creative potential of hallucinations</h2><p>Hassabis discussed AlphaEvolve, a system where AI models generate hypotheses and explore new solutions through evolutionary programming. This represents a step towards automated scientific discovery and even self-improvement. Interestingly, he reframes "hallucination" – often seen as a flaw – as a potential source of creativity or "imagination" when guided, allowing models to explore novel ideas beyond their training data.</p><p>o&nbsp;&nbsp; <strong>Quote (on AlphaEvolve):</strong> "Well, at a high level, it's basically taking our latest Gemini models, actually two different ones, to generate sort of ideas, hypotheses about programs and other mathematical functions. And then it goes, they go into sort of evolutionary programming process to decide which ones of those are most promising."</p><p>o&nbsp;&nbsp; <strong>Quote (on "creative hallucination"):</strong> "Yes, well, I think that's right. I think, you know, hallucination in when you want factual things, obviously, is you don't want, but in creative situations where, you know, you can think of it as a little bit like lateral thinking in an MBA course or something, right? Is just create some crazy ideas. Most of them don't make sense. But the odd one or two may get you to a region of the search space that is actually quite valuable, it turns out, once you evaluate it afterwards. And so you can substitute the word hallucination maybe for imagination at that point, right? There's obviously two sides of the same coin."</p><h2>The dual approach to AI development: Massive scale and specialized models, incremental progress and breakthroughs</h2><p>Hassabis emphasized that progress towards AGI requires a multi-pronged strategy. This involves both scaling up large general models (like Gemini) which act as "teacher models," and developing smaller, efficient "flash models" for specific tasks. Similarly, advancement comes from both continuous, incremental improvements and dedicated "blue sky" research aimed at fundamental breakthroughs.</p><p>o&nbsp;&nbsp; <strong>Quote (on large and small models):</strong> "Well, I think you need those big models. We're, you know, we love big and small models. So you need the big models often to train the smaller models... And, but if you're interested in AGI, you've got to push the, again, both sides of that. It's not an either or in my mind. I'm an and, right? Like let's scale. Let's look at specialized techniques, combining that in hybrid systems sometimes they're called. And let's look at new blue sky research that could deliver the next transformers."</p><p>o&nbsp;&nbsp; <strong>Quote (on incremental and breakthrough research):</strong> "I think it could be both. And I think for sure both is gonna be useful, which is why we push unbelievably hard on the scaling and the, you know, what you would call incremental... And then on top of that, we're doing more greenfield things, more blue sky things, like Alpha Evolve, maybe you could include in that, which could bring in-- ...that could bring that sort of step change, as well as the incremental."</p><h2>AI for human flourishing: from attention protection to radical abundance </h2><p>Hassabis envisioned AI not just as a productivity tool but as a means to enhance human life significantly. He proposes AI assistants that can protect our attention from the deluge of digital noise, curating information for us. Further out, he sees AGI potentially leading to "radical abundance," solving major resource constraints, though this will bring political challenges regarding distribution.</p><p>o&nbsp;&nbsp; <strong>Quote (on AI as an attention protector):</strong> "My view on this is more through the lens of the universal assistant that we talked about yesterday... I feel like if this assistant becomes really useful and knows you well, you could sort of program it with you, obviously with natural language to protect your attention. So you could almost think of it as a system that works for you, you know, as an individual, it's yours. And it protects your attention from being assaulted by other algorithms that want your attention..."</p><p>o&nbsp;&nbsp; <strong>Quote (on radical abundance):</strong> "I also think that as we get closer to AGI and we make breakthroughs... we should start getting to a position in society where we're getting towards what I would call radical abundance, where there's a lot of resources to go around. And then again, it's more of a political question of how would you distribute that in a fair way, right?"</p><h2>The enduring value of human creativity and experience, especially in art</h2><p>While acknowledging AI's rapidly growing capabilities, Hassabis believes there's a fundamental aspect of human creativity, tied to lived experience, struggle, and "soul," that AI may not replicate, particularly in art. Even if AI can technically mimic human output, the knowledge of its artificial origin might diminish its connection with the audience.</p><p>o&nbsp;&nbsp; <strong>Quote:</strong> "That's why even like a novel, maybe Al could write one day a novel that's sort of technically good, but I don't think it would have the same soul or connection to the reader that if you knew it was written by an AI, at least as far as I can see for now... It's just always gonna feel something's missing. It's a sort of a soul for a better word of the piece, you know, the real humanity, the magic, if you like, the great pieces of art... When I see a Van Gogh or Rothko or, you know, why does that touch your, you know, I can spill, you know, sort of, you know, hairs gone on the back of my spine because I remember, you know, and you know about what they went through and the struggle to produce that, right?"</p></div>
</body>
</html>