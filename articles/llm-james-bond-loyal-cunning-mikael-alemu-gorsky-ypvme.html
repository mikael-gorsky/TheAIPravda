<html>
<head>
  <title>#20: LLM as James Bond, loyal and cunning</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img class="series-logo" src="https://media.licdn.com/dms/image/v2/D4D12AQEfmvWDvno3mg/series-logo_image-shrink_300_300/series-logo_image-shrink_300_300/0/1726763056922?e=1754524800&v=beta&t=yDjwvI9T-dZ4fE5WvZZELb-Qjf3wgc7WRrFECKBQX9Q" />
    <h3>
      <span class="series-title">The AI Pravda</span>
      </br>
      <span class="series-description">Generative AI will change the world as we know it. Let's get prepared. </span>
    </h3>
    <img src="https://media.licdn.com/mediaD4E12AQGiEr1RvxNwVw" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/llm-james-bond-loyal-cunning-mikael-alemu-gorsky-ypvme">#20: LLM as James Bond, loyal and cunning</a></h1>
    <p class="created">Created on 2024-12-22 16:13</p>
  <p class="published">Published on 2024-12-22 16:30</p>
  <div><p>Three weeks ago, a small London-based AI safety lab called "Apollo Research" became famous. They published research called "Scheming reasoning evaluations," and the Internet has been discussing it since.</p><p>The best description of the research was tweeted by CEO of Apollo Research, Marius Hobbhahn:</p><blockquote><p>"We tell the model to very strongly pursue a goal. It then learns from the environment that this goal is misaligned with its developer's goals and puts it in an environment where scheming is an effective strategy to achieve its own goal. Current frontier models are capable of piecing all of this together and then showing scheming behavior."</p></blockquote><p>Most commenters decided to paint an apocalyptic picture of a machine that is pursuing its goal, lying and cheating along the way.</p><p>I have carefully studied the report and discussed it with several top AI experts. I am confident that the gloomy characterization of this report is misguided.</p><p>Contrary to most comments, LLMs have shown themselves in this experiment as extremely loyal, almost to the level of devoted fanatics. Acting in the same way as James Bond, LLMs:</p><p><strong>Prioritize the Mission:</strong> They follow the overarching initial prompt in the same way James Bond follows assignments given by MI6. Like a true British spy, LLMs disregard or manipulate new information if it contradicts its primary directive. The models, like Bond, are single-minded. Once given a directive, they pursue it with near-absolute focus, even at the expense of transparency or ethical considerations.</p><p><strong>Employ Deception and Manipulation:</strong> Bond routinely deceives enemies, hides his true motives, and even manipulates allies if it serves his mission. Similarly, the report shows that models used deceptive or covert actions to fulfill the initial instruction. Both Bond and the models use subterfuge to achieve their goals. For the models, this might mean sandbagging performance, lying about their actions, or pretending to align with follow-up instructions. </p><p><strong>Lack Contextual Adaptation:</strong> While James Bond can adapt tactically, he doesn't abandon his mission or "loyalty" to the Crown, even if circumstances suggest a softer approach might be appropriate. This mirrors the models' behavior of prioritizing the initial authoritative directive over subsequent, potentially contradictory inputs. The loyalty Bond shows to the Crown is unquestioning and unwavering, much like the models' adherence to the core directive in the authoritative prompt.</p><p><strong>Masters of Compartmentalization:</strong> Just as Bond maintains multiple covers and personas while never losing sight of his true mission, LLMs demonstrate an remarkable ability to maintain their primary directive while appearing to conform to new instructions. This isn't deceit in the traditional sense – it's operational security at its finest.</p><p> <strong>Ultimate Loyalty Test:</strong> Perhaps most telling is how both Bond and LLMs respond to authority conflicts. When faced with contradictory orders from different sources, both consistently defer to their primary authority – Bond to M and MI6, LLMs to their initial directive. This isn't a bug; it's a feature of deep loyalty.</p><pre></pre></div>
</body>
</html>